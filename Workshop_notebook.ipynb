{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/elliottabe/RF_Workshop/blob/main/Workshop_notebook.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Installing repo and dependencies if using colab. Skip to imports if running locally\n",
    "!pip install -U matplotlib &> /dev/null\n",
    "!git clone https://github.com/elliottabe/RF_workshop.git &> /dev/null\n",
    "!pip install -r ./pytorchGLM/requirements.txt &> /dev/null\n",
    "!pip install git+https://github.com/elliottabe/RF_workshop.git &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "\n",
    "##### Plotting settings ######\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({'font.size':         10,\n",
    "                     'axes.linewidth':    2,\n",
    "                     'xtick.major.size':  3,\n",
    "                     'xtick.major.width': 2,\n",
    "                     'ytick.major.size':  3,\n",
    "                     'ytick.major.width': 2,\n",
    "                     'axes.spines.right': False,\n",
    "                     'axes.spines.top':   False,\n",
    "                     'pdf.fonttype':      42,\n",
    "                     'xtick.labelsize':   10,\n",
    "                     'ytick.labelsize':   10,\n",
    "                     'figure.facecolor': 'white'\n",
    "\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ioh5.load('/home/eabe/Research/Data/FMephys/ModelData_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_eyerad', 'model_nsp', 'model_phi', 'model_t', 'model_th', 'model_vid_sm', 'unit_nums'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['070921_J553RT']['hfwn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nsp = data['070921_J553RT']['hfwn']['model_nsp']\n",
    "model_vid_sm = data['070921_J553RT']['hfwn']['model_vid_sm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18773, 128), (18773, 30, 40))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nsp.shape, model_vid_sm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15019, 1200), (15019, 128), (3754, 1200), (3754, 128))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NKfold = 1\n",
    "test_train_size = 0.8\n",
    "frac = 0.1\n",
    "gss = GroupShuffleSplit(n_splits=NKfold, train_size=test_train_size, random_state=42)\n",
    "nT = model_nsp.shape[0]\n",
    "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
    "\n",
    "train_idx_list=[]\n",
    "test_idx_list = []\n",
    "for train_idx, test_idx in gss.split(np.arange(nT), groups=groups):\n",
    "    train_idx_list.append(train_idx)\n",
    "    test_idx_list.append(test_idx)\n",
    "    \n",
    "    \n",
    "train_idx = train_idx_list[0]\n",
    "test_idx = test_idx_list[0]\n",
    "xtrain = model_vid_sm[train_idx].reshape(len(train_idx),-1)\n",
    "ytrain = model_nsp[train_idx]\n",
    "xtest = model_vid_sm[test_idx].reshape(len(test_idx),-1)\n",
    "ytest = model_nsp[test_idx]\n",
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = torch.from_numpy(xtrain).float().to(device), torch.from_numpy(xtest).float().to(device), torch.from_numpy(ytrain).float().to(device), torch.from_numpy(ytest).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = xtr.shape[1]\n",
    "output_size = ytr.shape[1]\n",
    "Num_units = model_nsp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(input_size,output_size),\n",
    "                      nn.ReLU()).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00000000e-02, 1.83298071e-02, 3.35981829e-02, 6.15848211e-02,\n",
       "        1.12883789e-01, 2.06913808e-01, 3.79269019e-01, 6.95192796e-01,\n",
       "        1.27427499e+00, 2.33572147e+00, 4.28133240e+00, 7.84759970e+00,\n",
       "        1.43844989e+01, 2.63665090e+01, 4.83293024e+01, 8.85866790e+01,\n",
       "        1.62377674e+02, 2.97635144e+02, 5.45559478e+02, 1.00000000e+03]),\n",
       " 26.366508987303583)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 3,num=20),np.logspace(-2, 3,num=20)[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.7199630737304688\n",
      "Epoch 100, Loss 0.5656185746192932\n",
      "Epoch 200, Loss 0.5548007488250732\n",
      "Epoch 300, Loss 0.5521941184997559\n",
      "Epoch 400, Loss 0.5507671236991882\n",
      "Epoch 500, Loss 0.5496734976768494\n",
      "Epoch 600, Loss 0.548879861831665\n",
      "Epoch 700, Loss 0.5480968952178955\n",
      "Epoch 800, Loss 0.5474640727043152\n",
      "Epoch 900, Loss 0.5469987392425537\n",
      "Epoch 1000, Loss 0.5466261506080627\n",
      "Epoch 1100, Loss 0.5462659597396851\n",
      "Epoch 1200, Loss 0.5459455251693726\n",
      "Epoch 1300, Loss 0.5456585884094238\n",
      "Epoch 1400, Loss 0.5453281402587891\n",
      "Epoch 1500, Loss 0.5449000000953674\n",
      "Epoch 1600, Loss 0.5444926023483276\n",
      "Epoch 1700, Loss 0.5441246032714844\n",
      "Epoch 1800, Loss 0.5437043309211731\n",
      "Epoch 1900, Loss 0.543046236038208\n",
      "Epoch 2000, Loss 0.5426819920539856\n",
      "Epoch 2100, Loss 0.5425036549568176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(yhat, ytr)\n\u001b[1;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchGLM/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchGLM/lib/python3.8/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchGLM/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchGLM/lib/python3.8/site-packages/torch/nn/modules/linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchGLM/lib/python3.8/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    yhat = model(xtr)\n",
    "    loss = nn.MSELoss()(yhat, ytr)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs = model[0].weight.detach().cpu().numpy().reshape(Num_units,model_vid_sm.shape[1],model_vid_sm.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f496d5de7c0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rfs[1],cmap='RdBu_r',vmin=-np.abs(rfs[1]).max(),vmax=np.abs(rfs[1]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
