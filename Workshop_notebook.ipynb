{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/elliottabe/RF_Workshop/blob/main/Workshop_notebook.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Installing repo and dependencies if using colab. Skip to imports if running locally\n",
    "!pip install -U matplotlib &> /dev/null\n",
    "!git clone https://github.com/elliottabe/RF_workshop.git &> /dev/null\n",
    "!pip install -r ./RF_workshop/requirements.txt &> /dev/null\n",
    "# !pip install git+https://github.com/elliottabe/RF_workshop.git &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "file_id = '1AUYAmfQp3Hh25uf_mohaT3N3qLXKlMeo' # File id to example data\n",
    "output_file = 'data.h5'\n",
    "\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import RF_workshop.io_dict_to_hdf5 as ioh5\n",
    "\n",
    "##### Plotting settings ######\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({'font.size':         10,\n",
    "                     'axes.linewidth':    2,\n",
    "                     'xtick.major.size':  3,\n",
    "                     'xtick.major.width': 2,\n",
    "                     'ytick.major.size':  3,\n",
    "                     'ytick.major.width': 2,\n",
    "                     'axes.spines.right': False,\n",
    "                     'axes.spines.top':   False,\n",
    "                     'pdf.fonttype':      42,\n",
    "                     'xtick.labelsize':   10,\n",
    "                     'ytick.labelsize':   10,\n",
    "                     'figure.facecolor': 'white'\n",
    "\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ioh5.load('./data.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nsp = data['model_nsp']\n",
    "model_vid_sm = data['model_vid_sm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nsp.shape, model_vid_sm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receptive field (RF) mapping is classically done with reverse correlation (spike triggered averages). The basics can be done with simple linear algebra, but the reverse correlation becomes computationally expensive when dealing with high dimensional inputs. In this workshop, we will cover how to map RFs with a simple neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train/test split functions\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the temporal correlations in visual data, we do a group shuffle split where nonoverlapping 10\\% chunks of the data are split and randomly shuffled to generate our train and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NKfold = 1 # Number of Kfolds for the shuffle\n",
    "train_size = 0.8 # Fraction of data used for training set\n",
    "frac = 0.1 # fraction of the data to create chunks\n",
    "gss = GroupShuffleSplit(n_splits=NKfold, train_size=train_size, random_state=42)\n",
    "nT = model_nsp.shape[0] # Number of timepoints\n",
    "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)]) # defining groups\n",
    "\n",
    "# Create list of train and test indicies\n",
    "train_idx_list=[]\n",
    "test_idx_list = []\n",
    "for train_idx, test_idx in gss.split(np.arange(nT), groups=groups):\n",
    "    train_idx_list.append(train_idx)\n",
    "    test_idx_list.append(test_idx)\n",
    "    \n",
    "# Defining train and test datasets, with option to crop images. \n",
    "cropn = 0\n",
    "train_idx = train_idx_list[0]\n",
    "test_idx = test_idx_list[0]\n",
    "if cropn>0:\n",
    "    xtrain = model_vid_sm[train_idx][:,cropn:-cropn,cropn:-cropn]\n",
    "    xtest = model_vid_sm[test_idx][:,cropn:-cropn,cropn:-cropn]\n",
    "else: \n",
    "    xtrain = model_vid_sm[train_idx]\n",
    "    xtest = model_vid_sm[test_idx]\n",
    "im_size = xtrain.shape[1:]\n",
    "xtrain = xtrain.reshape(len(train_idx),-1)\n",
    "xtest = xtest.reshape(len(test_idx),-1)\n",
    "ytrain = model_nsp[train_idx]\n",
    "ytest = model_nsp[test_idx]\n",
    "\n",
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch uses the tensor datastructure, here we load the numpy arrays into tensors and put them onto the gpu for processing if available\n",
    "xtr, xte, ytr, yte = torch.from_numpy(xtrain).float().to(device), torch.from_numpy(xtest).float().to(device), torch.from_numpy(ytrain).float().to(device), torch.from_numpy(ytest).float().to(device)\n",
    "\n",
    "# creating some variables to keep track of dimensions\n",
    "input_size = xtr.shape[1]\n",
    "output_size = ytr.shape[1]\n",
    "Num_units = model_nsp.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a coding base used to train deep neural networks. Here we use the predefined layers to create a simple generalized linear model (GLM). \n",
    "\n",
    "A model in pytorch is defined in a couple of different ways. The simplest example, used here, is with the nn.Sequential function. This function constructs a model based on predefined operations and pushes data through them sequentially. \n",
    "\n",
    "In this case we construct a single linear layer with an output ReLU nonlinearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model parameters, pytorch utilizes auto differentiation methods to compute the gradient with respect to a loss value. This is defined using the ```torch.optim``` module. A commonly used optimizer is the ADAM algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple case a with a single linear layer the input/output function is defined as: \n",
    "\n",
    "$y = f(Wx + b)$, where x is the inputs, y is the outputs, and W,b are learnable parameters. $f$ is a nonlinear function, in this case ReLU. \n",
    "\n",
    "W is a weight matrix which after training represents the receptive fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(input_size,output_size),\n",
    "                      nn.ReLU()).to(device)\n",
    "\n",
    "# Define optimizer and paramters to be learned. The learning rate (lr) represents how big of a step we go along the gradient\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=.1)\n",
    "\n",
    "# To train the model we must define a loss function. A simple one for this case is the mean-squared error (MSE). \n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When printing the model we can see it is built with a single Linear layer and ReLU activation fuction. \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable 'model' holds all the parameters that will be used to learn the mapping between our inputs and outputs. We can inspect them using the following code: \n",
    "for name,p in model.named_parameters():\n",
    "    print('{}: {}'.format(name, p.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further inspectin the weights we see that the weights have the flag requires_grad=True meaning every operation is tracked for the gradient calculation. \n",
    "print(model[0].weight)\n",
    "# Before performing the backwards pass we see there is no gradient information in our paremters\n",
    "print(model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add regularization into the model we can calculate additional terms and add them to the loss. L1 and L2 regularization are common in regression. L2 regularization (ridge regression) is already implemented in the optimizers and is used by adding a weight_decay value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted output\n",
    "yhat = model(xtr)\n",
    "print(yhat.shape)\n",
    "# Calculate the loss value\n",
    "loss_value = criterion(yhat,ytr)\n",
    "print(loss_value)\n",
    "\n",
    "# Add L2 regularization with weight_decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=.1)\n",
    "# Calculate loss with L1 regularization\n",
    "l1_alpha = 0.0001 # strength of L1 regularization\n",
    "loss_value = criterion(yhat,ytr) + l1_alpha*torch.norm(model[0].weight,p=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update the paraemters of our model based we must first call the backwards pass. \n",
    "\n",
    "# Make sure to clear gradient before calculating backwards pass just in case. \n",
    "optimizer.zero_grad()\n",
    "# backwards pass\n",
    "loss_value.backward()\n",
    "\n",
    "# Now we see that the parameters have a gradient value\n",
    "print('Gradient of weights:',model[0].weight.grad)\n",
    "print('Parameters before update:',model[0].weight)\n",
    "# update parameters\n",
    "optimizer.step()\n",
    "print('Parameters after update:',model[0].weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the weights of the model have change. Now we can place these operations within a for loop and iterate through out data multiple times. \n",
    "\n",
    "Terminology:\n",
    "- Epoch: A single runthough the dataset\n",
    "- batch (minibatch): when not all the data can be loaded on to the gpu at the same time, chunks of data are processed at a time. A batch represent one of these chunks. \n",
    "- batch size: represent how many chunks are processed in parallel. For example, data is often of the shape (batch_size, time, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nepochs = 2000 # Number of epochs\n",
    "l2_lambda_list = [.05,.1,1] # List of L2 regularzation strengths to iterate over\n",
    "l1_alpha = 0.0001 # Strength of L1 regularization\n",
    "min_loss = np.inf # define initial validation loss\n",
    "\n",
    "##### Use tqdm to visualize progress #####\n",
    "with tqdm(initial=0,total=len(l2_lambda_list), dynamic_ncols=False, miniters=1) as tq:\n",
    "    ##### Loop through the different L2 values\n",
    "    for l2_lambda in l2_lambda_list:\n",
    "        ##### For each L2 value we define a new model to train #####\n",
    "        model = nn.Sequential(nn.Linear(input_size,output_size),\n",
    "                            nn.ReLU()).to(device)\n",
    "        ##### Define the optimizer for learning #####\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=l2_lambda)\n",
    "        \n",
    "        ##### Training loop ####\n",
    "        for epoch in tqdm(range(Nepochs),leave=False):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(xtr)\n",
    "            train_loss = nn.MSELoss()(yhat, ytr) + l1_alpha*torch.norm(model[0].weight,p=1)\n",
    "            train_loss.backward(torch.ones_like(train_loss))\n",
    "            optimizer.step()\n",
    "    \n",
    "        ##### Check on validation data ####\n",
    "        yhat = model(xte)\n",
    "        ##### Calculate validation loss #####\n",
    "        val_loss = nn.MSELoss()(yhat, yte)  + l1_alpha*torch.norm(model[0].weight,p=1)\n",
    "        \n",
    "        #### If validation loss is new minimum save, and save model parameters ####\n",
    "        if val_loss < min_loss:\n",
    "            l2_lambda_min = l2_lambda\n",
    "            torch.save(model.state_dict(),'./RF_l2_min.pt')\n",
    "            min_loss = val_loss\n",
    "        \n",
    "        ##### Update visualziation progress #### \n",
    "        tq.set_postfix(val_loss='{:05.3f}'.format(val_loss),train_loss='{:05.3f}'.format(train_loss),min_loss='{:05.3f}'.format(min_loss))\n",
    "        tq.update()\n",
    "        \n",
    "##### load best model #####\n",
    "load_model = torch.load('./RF_l2_min.pt')\n",
    "model.load_state_dict(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### The weights of our model represent the visual RFs so lets extract them. #####\n",
    "\n",
    "# To retreive them from the model and put them in a form that is more easily visualizable we have to detach the weights, put them on the cpu and change from tensor to numpy. \n",
    "RF = model[0].weight.detach().cpu().numpy().reshape(Num_units,im_size[0],im_size[1])\n",
    "RF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the RFs, lets plot them to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(13,10,figsize=(20,20))\n",
    "for n, ax in enumerate(range(RF.shape[0])):\n",
    "    ax = axs.flatten()[n]\n",
    "    cmax = np.max(np.abs(RF[n]))\n",
    "    ax.imshow(RF[n],cmap='RdBu_r',vmin=-cmax,vmax=cmax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data provided, we also have the calculated RFs from Parker, Abe, et. al. 2022 and we can compare. \n",
    "\n",
    "Note: In the paper we thresholded out some neruons due to firing rate and duplication. The data we used to map the receptive fields today have not been filtered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_vis = data['RF_vis']\n",
    "\n",
    "RF_vis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(13,10,figsize=(20,20))\n",
    "for n, ax in enumerate(range(RF_vis.shape[0])):\n",
    "    ax = axs.flatten()[n]\n",
    "    cmax = np.max(np.abs(RF_vis[n]))\n",
    "    ax.imshow(RF_vis[n,2],cmap='RdBu_r',vmin=-cmax,vmax=cmax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional STA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are no nans in the data\n",
    "xtr[torch.isnan(xtr)] = 0\n",
    "\n",
    "# Compute the STA\n",
    "sta = xtr.T @ ytr\n",
    "sta = sta/torch.sum(ytr,dim=0,keepdim=True)\n",
    "\n",
    "# Reshape for visualization\n",
    "sta_all = sta.T.reshape(Num_units,im_size[0],im_size[1]).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the RFs\n",
    "fig, axs = plt.subplots(13,10,figsize=(20,20))\n",
    "for n, ax in enumerate(range(sta_all.shape[0])):\n",
    "    ax = axs.flatten()[n]\n",
    "    cmax = np.max(np.abs(sta_all[n]))\n",
    "    ax.imshow(sta_all[n],cmap='RdBu_r',vmin=-cmax,vmax=cmax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only calculated a RF for a single time point. To create a spatio-temporal receptive field we can add additional time delayed inputs to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NKfold = 1 # Number of Kfolds for the shuffle\n",
    "train_size = 0.8 # Fraction of data used for training set\n",
    "frac = 0.1 # fraction of the data to create chunks\n",
    "gss = GroupShuffleSplit(n_splits=NKfold, train_size=train_size, random_state=42)\n",
    "nT = model_nsp.shape[0] # Number of timepoints\n",
    "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)]) # defining groups\n",
    "\n",
    "# Create list of train and test indicies\n",
    "train_idx_list=[]\n",
    "test_idx_list = []\n",
    "for train_idx, test_idx in gss.split(np.arange(nT), groups=groups):\n",
    "    train_idx_list.append(train_idx)\n",
    "    test_idx_list.append(test_idx)\n",
    "    \n",
    "# Defining train and test datasets, with option to crop images. \n",
    "cropn = 0\n",
    "train_idx = train_idx_list[0]\n",
    "test_idx = test_idx_list[0]\n",
    "if cropn>0:\n",
    "    xtrain = model_vid_sm[train_idx][:,cropn:-cropn,cropn:-cropn]\n",
    "    xtest = model_vid_sm[test_idx][:,cropn:-cropn,cropn:-cropn]\n",
    "else: \n",
    "    xtrain = model_vid_sm[train_idx]\n",
    "    xtest = model_vid_sm[test_idx]\n",
    "im_size = xtrain.shape[1:]\n",
    "xtrain = xtrain.reshape(len(train_idx),-1)\n",
    "xtest = xtest.reshape(len(test_idx),-1)\n",
    "ytrain = model_nsp[train_idx]\n",
    "ytest = model_nsp[test_idx]\n",
    "\n",
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [-1,0,1]\n",
    "xtrain = np.hstack([np.roll(xtrain, nframes, axis=0) for nframes in lag_list])\n",
    "xtest = np.hstack([np.roll(xtest, nframes, axis=0) for nframes in lag_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch uses the tensor datastructure, here we load the numpy arrays into tensors and put them onto the gpu for processing if available\n",
    "xtr, xte, ytr, yte = torch.from_numpy(xtrain).float().to(device), torch.from_numpy(xtest).float().to(device), torch.from_numpy(ytrain).float().to(device), torch.from_numpy(ytest).float().to(device)\n",
    "\n",
    "# creating some variables to keep track of dimensions\n",
    "input_size = xtr.shape[1]\n",
    "output_size = ytr.shape[1]\n",
    "Num_units = model_nsp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nepochs = 2000 # Number of epochs\n",
    "l2_lambda_list = [.1] # List of L2 regularzation strengths to iterate over\n",
    "l1_alpha = 0.0001 # Strength of L1 regularization\n",
    "min_loss = np.inf # define initial validation loss\n",
    "\n",
    "##### Use tqdm to visualize progress #####\n",
    "with tqdm(initial=0,total=len(l2_lambda_list), dynamic_ncols=False, miniters=1) as tq:\n",
    "    ##### Loop through the different L2 values\n",
    "    for l2_lambda in l2_lambda_list:\n",
    "        ##### For each L2 value we define a new model to train #####\n",
    "        model = nn.Sequential(nn.Linear(input_size,output_size),\n",
    "                            nn.ReLU()).to(device)\n",
    "        ##### Define the optimizer for learning #####\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=l2_lambda)\n",
    "        \n",
    "        ##### Training loop ####\n",
    "        for epoch in tqdm(range(Nepochs),leave=False):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(xtr)\n",
    "            train_loss = nn.MSELoss()(yhat, ytr) + l1_alpha*torch.norm(model[0].weight,p=1)\n",
    "            train_loss.backward(torch.ones_like(train_loss))\n",
    "            optimizer.step()\n",
    "    \n",
    "        ##### Check on validation data ####\n",
    "        yhat = model(xte)\n",
    "        ##### Calculate validation loss #####\n",
    "        val_loss = nn.MSELoss()(yhat, yte)  + l1_alpha*torch.norm(model[0].weight,p=1)\n",
    "        \n",
    "        #### If validation loss is new minimum save, and save model parameters ####\n",
    "        if val_loss < min_loss:\n",
    "            l2_lambda_min = l2_lambda\n",
    "            torch.save(model.state_dict(),'./RF_l2_min_spatiotemporal.pt')\n",
    "            min_loss = val_loss\n",
    "        \n",
    "        ##### Update visualziation progress #### \n",
    "        tq.set_postfix(val_loss='{:05.3f}'.format(val_loss),train_loss='{:05.3f}'.format(train_loss),min_loss='{:05.3f}'.format(min_loss))\n",
    "        tq.update()\n",
    "        \n",
    "##### load best model #####\n",
    "load_model = torch.load('./RF_l2_min_spatiotemporal.pt')\n",
    "model.load_state_dict(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing RFs from model\n",
    "RF_ST = model[0].weight.detach().cpu().numpy().reshape(Num_units,len(lag_list),im_size[0],im_size[1])\n",
    "RF_ST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = [4,7,63,120,125]\n",
    "fig, axs = plt.subplots(len(n_neurons),3,figsize=(15,12))\n",
    "for n, ax in enumerate(n_neurons):\n",
    "    cmax = np.max(np.abs(RF_ST[n]))\n",
    "    for k in range(len(lag_list)):\n",
    "        ax = axs[n,k]\n",
    "        ax.imshow(RF_ST[n,k],cmap='RdBu_r',vmin=-cmax,vmax=cmax)\n",
    "        ax.axis('off')\n",
    "        ax.set_title('Unit:{},t={}'.format(n_neurons[n],lag_list[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
